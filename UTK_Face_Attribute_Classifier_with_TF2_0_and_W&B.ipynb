{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ayulockin/faceattributes/blob/master/UTK_Face_Attribute_Classifier_with_TF2_0_and_W%26B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zz3iTPuGsFk0"
   },
   "source": [
    "## Initial Setup and Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IQQ518Z7e64a"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -q\n",
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_4P9llJrbnwb",
    "outputId": "5c7dbba5-768e-49c5-cbf5-4a581639c94b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xtlXgh2A_quQ"
   },
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2BHbM3zsLE2"
   },
   "source": [
    "## Clone project repo and set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "EWylfsNyPhmp",
    "outputId": "741fd7f4-274b-40d0-87f7-4b73f5e5aebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'faceattributes'...\n",
      "remote: Enumerating objects: 23388, done.\u001b[K\n",
      "remote: Total 23388 (delta 0), reused 0 (delta 0), pack-reused 23388\u001b[K\n",
      "Receiving objects: 100% (23388/23388), 115.72 MiB | 42.39 MiB/s, done.\n",
      "Resolving deltas: 100% (12/12), done.\n",
      "Checking out files: 100% (23749/23749), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ayulockin/faceattributes.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Uoyqfd6QY5H2",
    "outputId": "6a952b73-91e3-4635-c760-7b9890841f3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faceattributes\tsample_data  wandb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZhVrxU5tZH6B",
    "outputId": "fe6a3386-7a19-4671-d9b3-c4d0a6a3a7a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/faceattributes\n"
     ]
    }
   ],
   "source": [
    "%cd faceattributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "EOm8oSTWZMms",
    "outputId": "b1c6ec0f-7329-4e2b-ad26-b4ae6aba6bf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " datasets\t\t      face_detector   prepareUTKFaceData.py\n",
      "'EDA of Face Dataset.ipynb'   images\t      README.md\n",
      " examples\t\t      LICENSE\t      test.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rei5ajLsZfAz",
    "outputId": "602405dc-b266-4ae6-fa06-3b082e6b3802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images:  23705\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "images = os.listdir('images')\n",
    "print('Total number of images: ', len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8BajKv1NyOlb"
   },
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nK2DgE2ELf7Z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eNd4wXsEKJPV"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('datasets/face_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "VSaia-E6yGYv",
    "outputId": "67428410-fde2-422a-8d68-37632f24a836"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teripprmot</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ibjkghymsu</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dlsaxmcymo</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oyyopnhvza</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nhufelmwaw</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fkozflztvo</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jfjtfckikm</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>exeinekyai</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ynybxuwyrx</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pkwnjssqij</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id  age  gender  ethnicity\n",
       "0  teripprmot  100       0          0\n",
       "1  ibjkghymsu  100       0          0\n",
       "2  dlsaxmcymo  100       1          0\n",
       "3  oyyopnhvza  100       1          0\n",
       "4  nhufelmwaw  100       1          0\n",
       "5  fkozflztvo  100       1          0\n",
       "6  jfjtfckikm  100       1          0\n",
       "7  exeinekyai  100       1          0\n",
       "8  ynybxuwyrx  100       1          2\n",
       "9  pkwnjssqij  100       1          2"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iMV1v9c9-KgC"
   },
   "source": [
    "> For each image there are three labels. Since we are building a multi-output classifier we need to prepare the dataset accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "ulOGkLl5Z-u4",
    "outputId": "590fe0f8-c18d-4048-f4c1-4b891f5ce388"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_id     23705\n",
       "age          23705\n",
       "gender       23705\n",
       "ethnicity    23705\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVyV3bgPSyBU"
   },
   "outputs": [],
   "source": [
    "# Shuffle dataframe\n",
    "labels = labels.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSTHu3s8vbfP"
   },
   "source": [
    "## Helper Function\n",
    "\n",
    "Refer EDA of the dataset for more insight into this.\n",
    "Click [here](https://github.com/ayulockin/faceattributes/blob/master/EDA%20of%20Face%20Dataset.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "He-MfNa1MYqG"
   },
   "outputs": [],
   "source": [
    "def groupAge(age):\n",
    "#     [0, 5, 18, 24, 26, 27, 30, 34, 38, 46, 55, 65, len(ages)])\n",
    "    if age>=0 and age<5:\n",
    "        return 0\n",
    "    elif age>=5 and age<18:\n",
    "        return 1\n",
    "    elif age>=18 and age<24:\n",
    "        return 2\n",
    "    elif age>=24 and age<26:\n",
    "        return 3\n",
    "    elif age>=26 and age<27:\n",
    "        return 4\n",
    "    elif age>=27 and age<30:\n",
    "        return 5\n",
    "    elif age>=30 and age<34:\n",
    "        return 6\n",
    "    elif age>=34 and age<38:\n",
    "        return 7\n",
    "    elif age>=38 and age<46:\n",
    "        return 8\n",
    "    elif age>=46 and age<55:\n",
    "        return 9\n",
    "    elif age>=55 and age<65:\n",
    "        return 10\n",
    "    else:\n",
    "        return 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQSJNPDhvUHI"
   },
   "source": [
    "## Prepare Data for training and validation\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hIAngPQdNJ0E"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IjSYmVPUwtYu"
   },
   "source": [
    "#### Train-validation-test Split \n",
    "\n",
    "Tasks performed by this cell:\n",
    "1. Split into train-validation-test in the ratio of 70:20:10\n",
    "2. Create age group. Refer EDA of the dataset.\n",
    "3. One hot encode each label.\n",
    "4. Create separate labels for separate parts of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M34zx0uxLwoH"
   },
   "outputs": [],
   "source": [
    "def formatdata(train_count, validation_count, test_count):\n",
    "  partitions = {'train': [],\n",
    "                'validation': [],\n",
    "                'test': []}\n",
    "  labels_dict = {'train_age': [], 'train_gender': [], 'train_ethnicity': [],\n",
    "                 'validation_age': [], 'validation_gender': [], 'validation_ethnicity': [],\n",
    "                 'test_age': [], 'test_gender': [], 'test_ethnicity': []}\n",
    "  random.seed(1)\n",
    "\n",
    "  print(\"[INFO] Preparing train data....\")\n",
    "  for ID in range(train_count):\n",
    "    try:\n",
    "        data = labels.loc[labels['image_id'] == images[ID][:-4]].values\n",
    "        labels_dict['train_age'].append(to_categorical(groupAge(data[0][1]), num_classes=12, dtype='float32'))\n",
    "        labels_dict['train_gender'].append(data[0][2])\n",
    "        labels_dict['train_ethnicity'].append(to_categorical(data[0][3], num_classes=5, dtype='float32'))\n",
    "        partitions['train'].append(images[ID])\n",
    "    except IndexError:\n",
    "        print(\"[ERROR]\", images[ID])\n",
    "        discared_data.append(images[ID])\n",
    "  print(\"[INFO] Done\")\n",
    "\n",
    "  print(\"[INFO] Preparing validation data....\")\n",
    "  for ID in range(train_count, train_count+validation_count):\n",
    "    try:\n",
    "        data = labels.loc[labels['image_id'] == images[ID][:-4]].values\n",
    "        labels_dict['validation_age'].append(to_categorical(groupAge(data[0][1]), num_classes=12, dtype='float32'))\n",
    "        labels_dict['validation_gender'].append(data[0][2])\n",
    "        labels_dict['validation_ethnicity'].append(to_categorical(data[0][3], num_classes=5, dtype='float32'))\n",
    "        partitions['validation'].append(images[ID])\n",
    "    except IndexError:\n",
    "        print(\"[ERROR]\", images[ID])\n",
    "        discared_data.append(images[ID])\n",
    "  print(\"[INFO] Done\")\n",
    "\n",
    "  ## Uncomment to get test split\n",
    "  print(\"[INFO] Preparing test data....\")\n",
    "  for ID in range(train_count+validation_count, len(images)):\n",
    "    try:\n",
    "        data = labels.loc[labels['image_id'] == images[ID][:-4]].values\n",
    "        labels_dict['test_age'].append(to_categorical(groupAge(data[0][1]), num_classes=12, dtype='float32'))\n",
    "        labels_dict['test_gender'].append(data[0][2])\n",
    "        labels_dict['test_ethnicity'].append(to_categorical(data[0][3], num_classes=5, dtype='float32'))\n",
    "        partitions['test'].append(images[ID])\n",
    "    except IndexError:\n",
    "        print(\"[ERROR]\", images[ID])\n",
    "        discared_data.append(images[ID])\n",
    "  print(\"[INFO] Done\")\n",
    "\n",
    "  return partitions, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "iZ9a0YQGoS0U",
    "outputId": "d7286281-9d7e-4936-eb71-89b9f1dd5aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preparing train data....\n",
      "[INFO] Done\n",
      "[INFO] Preparing validation data....\n",
      "[INFO] Done\n",
      "[INFO] Preparing test data....\n",
      "[INFO] Done\n"
     ]
    }
   ],
   "source": [
    "# train:validation:test = 70:20:10 = 16596:4742:2370\n",
    "\n",
    "train_count = 5000  \n",
    "validation_count = 1000\n",
    "test_count = 100\n",
    "\n",
    "partitions, labels_dict = formatdata(train_count, validation_count, test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "1wGn9S7EPOQw",
    "outputId": "17d08300-b076-4900-fb69-0667a81b502a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training Data\n",
      "Size of train data:  5000\n",
      "Size of age as label:  5000\n",
      "Size of gender as label:  5000\n",
      "Size of ethnicity as label:  5000\n",
      "\n",
      "\n",
      "[INFO] Validation Data\n",
      "Size of validation data:  1000\n",
      "Size of age as label:  1000\n",
      "Size of gender as label:  1000\n",
      "Size of ethnicity as label:  1000\n",
      "\n",
      "\n",
      "[INFO] Test Data\n",
      "Size of test data:  17705\n",
      "Size of age as label:  17705\n",
      "Size of gender as label:  17705\n",
      "Size of ethnicity as label:  17705\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Training Data\")\n",
    "print(\"Size of train data: \", len(partitions['train']))\n",
    "print(\"Size of age as label: \", len(labels_dict['train_age']))\n",
    "print(\"Size of gender as label: \", len(labels_dict['train_gender']))\n",
    "print(\"Size of ethnicity as label: \", len(labels_dict['train_ethnicity']))\n",
    "print(\"\\n\")\n",
    "print(\"[INFO] Validation Data\")\n",
    "print(\"Size of validation data: \", len(partitions['validation']))\n",
    "print(\"Size of age as label: \", len(labels_dict['validation_age']))\n",
    "print(\"Size of gender as label: \", len(labels_dict['validation_gender']))\n",
    "print(\"Size of ethnicity as label: \", len(labels_dict['validation_ethnicity']))\n",
    "print(\"\\n\")\n",
    "# Uncomment to log test split details\n",
    "print(\"[INFO] Test Data\")\n",
    "print(\"Size of test data: \", len(partitions['test']))\n",
    "print(\"Size of age as label: \", len(labels_dict['test_age']))\n",
    "print(\"Size of gender as label: \", len(labels_dict['test_gender']))\n",
    "print(\"Size of ethnicity as label: \", len(labels_dict['test_ethnicity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FSR-Z0xwy9y6"
   },
   "source": [
    "#### Load images on the memory (Good old `x_train` and `x_val`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DL7C47zs9GD1"
   },
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnO1sr99QXqp"
   },
   "outputs": [],
   "source": [
    "def loadImages(images, imagesPath):\n",
    "    print(\"[INFO] Loading....\")\n",
    "    X = []\n",
    "    count = 0\n",
    "    for image in images:\n",
    "        if count%1000==0:\n",
    "            print(\"[INFO] {} images loaded\".format(count))\n",
    "        img = imageio.imread(imagesPath+'/'+image)\n",
    "        img = np.array(img)\n",
    "        X.append(img)\n",
    "        count+=1\n",
    "    print(\"[INFO] Done\")\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "9OzM-ln8QlHo",
    "outputId": "e5fa88dc-1bc6-405a-8a1c-ccfa740e578b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training Data\n",
      "[INFO] Loading....\n",
      "[INFO] 0 images loaded\n",
      "[INFO] 1000 images loaded\n",
      "[INFO] 2000 images loaded\n",
      "[INFO] 3000 images loaded\n",
      "[INFO] 4000 images loaded\n",
      "[INFO] Done\n",
      "[INFO] Validation Data\n",
      "[INFO] Loading....\n",
      "[INFO] 0 images loaded\n",
      "[INFO] Done\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Training Data\")\n",
    "trainX = loadImages(partitions['train'], 'images/')\n",
    "print(\"[INFO] Validation Data\")\n",
    "validationX = loadImages(partitions['validation'], 'images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KqTmGu_evcdz"
   },
   "outputs": [],
   "source": [
    "trainX = trainX/255.0\n",
    "validationX = validationX/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "xqa_mw0xRywC",
    "outputId": "6ffc5aed-d542-4930-8273-7e3f3037ef4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training Images:  (5000, 200, 200, 3)\n",
      "[INFO] Validation Images:  (1000, 200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Training Images: \", trainX.shape)\n",
    "print(\"[INFO] Validation Images: \", validationX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCwXqLxnzZ1C"
   },
   "source": [
    "#### Good old `y_train` and `y_val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WFvltSdAWTZn"
   },
   "outputs": [],
   "source": [
    "trainY = {\n",
    "    'gender': np.array(labels_dict['train_gender']),\n",
    "    'ethnicity': np.array(labels_dict['train_ethnicity']),\n",
    "    'age': np.array(labels_dict['train_age'])\n",
    "}\n",
    "\n",
    "validationY = {\n",
    "    'gender': np.array(labels_dict['validation_gender']),\n",
    "    'ethnicity': np.array(labels_dict['validation_ethnicity']),\n",
    "    'age': np.array(labels_dict['validation_age'])\n",
    "}\n",
    "\n",
    "trainY['gender'] = trainY['gender'].reshape(trainY['gender'].shape[0], 1)\n",
    "validationY['gender'] = validationY['gender'].reshape(validationY['gender'].shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "epLTZpULPMu5",
    "outputId": "19b833b2-17b4-4e44-dd1b-69c18b0504dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels\n",
      "[INFO] Shape of gender label:  (5000, 1)\n",
      "[INFO] Shape of ethnicity label:  (5000, 5)\n",
      "[INFO] Shape of age label:  (5000, 12)\n",
      "\n",
      "Validation labels\n",
      "[INFO] Shape of gender label:  (1000, 1)\n",
      "[INFO] Shape of ethnicity label:  (1000, 5)\n",
      "[INFO] Shape of age label:  (1000, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Training labels')\n",
    "print('[INFO] Shape of gender label: ', trainY['gender'].shape)\n",
    "print('[INFO] Shape of ethnicity label: ', trainY['ethnicity'].shape)\n",
    "print('[INFO] Shape of age label: ', trainY['age'].shape)\n",
    "print('\\nValidation labels')\n",
    "print('[INFO] Shape of gender label: ', validationY['gender'].shape)\n",
    "print('[INFO] Shape of ethnicity label: ', validationY['ethnicity'].shape)\n",
    "print('[INFO] Shape of age label: ', validationY['age'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_tVPfFnjaGx"
   },
   "source": [
    "## Weights and Biases configs and init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "smL7akzzjYqT",
    "outputId": "624fa228-e1e3-4768-aa23-9f3669dadc1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/ayush-thakur/multi-output-classifier\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/multi-output-classifier</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/ayush-thakur/multi-output-classifier/runs/kor6x8g7\" target=\"_blank\">https://app.wandb.ai/ayush-thakur/multi-output-classifier/runs/kor6x8g7</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/ayush-thakur/multi-output-classifier/runs/kor6x8g7"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initilize a new wandb run\n",
    "wandb.init(entity='ayush-thakur', project=\"multi-output-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4KHuohpjZqb"
   },
   "outputs": [],
   "source": [
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EuT4FDWb5KP"
   },
   "outputs": [],
   "source": [
    "config.update(params={'epochs':5, 'gender_loss_wt': 0.5, 'ethnicity_loss_wt':0.5, 'age_loss_wt': 1.0}, allow_val_change=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQw0eM_z2PTW"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "config.epochs = 5\n",
    "config.batch_size = 32\n",
    "config.shuffle_buffer = 64\n",
    "config.optimizer = 'adam'\n",
    "\n",
    "config.img_width=200\n",
    "config.img_height=200\n",
    "\n",
    "config.gender_classes = 2\n",
    "config.enthnicity_classes = 5\n",
    "config.age_classes = 12\n",
    "\n",
    "config.gender_loss_wt = 0.5\n",
    "config.ethnicity_loss_wt = 0.5\n",
    "config.age_loss_wt = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfrGYLDcz0jl"
   },
   "source": [
    "#### Harness the power of `tf.data` input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwjhDadWgq4i"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5aaF_tiWgbv"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((trainX, trainY))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validationX, validationY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "un-GDXIqbbjs"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.cache().\\\n",
    "    shuffle(buffer_size=config.shuffle_buffer).\\\n",
    "    repeat().\\\n",
    "    batch(config.batch_size).\\\n",
    "    prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzQc2P6obwE6"
   },
   "outputs": [],
   "source": [
    "validation_dataset = validation_dataset.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1RQyE033u-Cx"
   },
   "source": [
    "## Build a Multi-Output Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pOoUGDUGeEkB"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_93iQFOdmUl"
   },
   "outputs": [],
   "source": [
    "def gender_classifier(inputLayer):\n",
    "    x = Conv2D(32, kernel_size=(3,3), padding='same', activation='relu')(inputLayer)\n",
    "    x = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=(3,3), padding='valid', activation='relu')(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(256, kernel_size=(3,3), padding='valid', activation='relu')(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(config.gender_classes, activation='sigmoid', name='gender')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aF4p8DnAeVdx"
   },
   "outputs": [],
   "source": [
    "def ethnicity_classifier(inputLayer):\n",
    "    x = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(inputLayer)\n",
    "    x = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(inputLayer)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(64, kernel_size=(3,3), padding='valid', activation='relu')(x)\n",
    "    x = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=(3,3), padding='valid', activation='relu')(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(256, kernel_size=(3,3), padding='valid', activation='relu')(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(config.enthnicity_classes, activation='softmax', name='ethnicity')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iEi981xBeaAx"
   },
   "outputs": [],
   "source": [
    "def age_classifier(inputLayer):\n",
    "    x = Conv2D(32, kernel_size=(3,3), padding='same', activation='relu')(inputLayer)\n",
    "    x = Conv2D(32, kernel_size=(3,3), padding='same', activation='relu')(inputLayer)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(64, kernel_size=(3,3), padding='valid', activation='relu')(x)\n",
    "    x = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=(3,3), padding='valid', activation='relu')(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(256, kernel_size=(3,3), padding='valid', activation='relu')(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(config.age_classes, activation='softmax', name='age')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6s5-o3yefP0"
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "inputLayer = Input(shape=(config.img_width,config.img_height,3))\n",
    "gender = gender_classifier(inputLayer)\n",
    "ethnicity = ethnicity_classifier(inputLayer)\n",
    "age = age_classifier(inputLayer)\n",
    "model = Model(inputs=inputLayer, outputs=[gender, ethnicity, age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BGM_pqB0ekXr",
    "outputId": "0ccf914c-0087-4df8-b657-e4f44fa3ac81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 200, 200, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 200, 200, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 100, 100, 32) 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 100, 100, 64) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 100, 100, 32) 128         max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 100, 100, 64) 256         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 100, 100, 32) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 200, 200, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100, 100, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 98, 98, 64)   18496       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 200, 200, 64) 18496       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 98, 98, 64)   36928       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 98, 98, 64)   36928       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 100, 100, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 98, 98, 64)   36928       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 49, 49, 64)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 100, 100, 64) 256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 49, 49, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 49, 49, 64)   256         max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100, 100, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 49, 49, 64)   256         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 49, 49, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 98, 98, 128)  73856       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 49, 49, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 47, 47, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 98, 98, 128)  147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 47, 47, 128)  73856       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 47, 47, 128)  147584      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 49, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 47, 47, 128)  147584      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 23, 23, 128)  0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 49, 49, 128)  512         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 23, 23, 128)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 23, 23, 128)  512         max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 49, 49, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 23, 23, 128)  512         max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 23, 23, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 47, 47, 256)  295168      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 23, 23, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 21, 21, 256)  295168      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 47, 47, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 21, 21, 256)  295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 21, 21, 256)  590080      conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 23, 23, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 21, 21, 256)  590080      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 10, 10, 256)  0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 23, 23, 256)  1024        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 10, 10, 256)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 10, 10, 256)  1024        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 23, 23, 256)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 10, 10, 256)  1024        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 10, 10, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 135424)       0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 25600)        0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          34668800    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 25600)        0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         26215424    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          13107712    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 512)          524800      dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          131328      dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          131328      dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 2)            130         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ethnicity (Dense)               (None, 5)            1285        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 12)           3084        dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 78,302,227\n",
      "Trainable params: 78,299,347\n",
      "Non-trainable params: 2,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1vP43AKmvGfO"
   },
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WrpqjhDSe9Rn"
   },
   "outputs": [],
   "source": [
    "losses = {\n",
    "    'gender': 'binary_crossentropy',\n",
    "    'ethnicity': 'categorical_crossentropy',\n",
    "    'age': 'categorical_crossentropy'\n",
    "}\n",
    "\n",
    "losses_weights = {\n",
    "    'gender': config.gender_loss_wt,\n",
    "    'ethnicity': config.ethnicity_loss_wt,\n",
    "    'age': config.age_loss_wt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdp2o3ypfDxJ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=config.optimizer, loss=losses, loss_weights=losses_weights, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7WEulVG2ay_"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "aXpnKrf7fLhM",
    "outputId": "bc03b1c3-4a46-4723-ef78-3586c350ca9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "156/156 [==============================] - 84s 539ms/step - loss: 3.9967 - gender_loss: 1.5049 - ethnicity_loss: 1.4991 - age_loss: 2.4947 - gender_accuracy: 0.6667 - ethnicity_accuracy: 0.5162 - age_accuracy: 0.1811 - val_loss: 4.4213 - val_gender_loss: 1.0303 - val_ethnicity_loss: 1.2949 - val_age_loss: 3.2587 - val_gender_accuracy: 0.5580 - val_ethnicity_accuracy: 0.4940 - val_age_accuracy: 0.0847\n",
      "Epoch 2/5\n",
      "156/156 [==============================] - 79s 505ms/step - loss: 2.7039 - gender_loss: 0.4441 - ethnicity_loss: 0.9293 - age_loss: 2.0172 - gender_accuracy: 0.8007 - ethnicity_accuracy: 0.6635 - age_accuracy: 0.2690 - val_loss: 3.3119 - val_gender_loss: 0.8328 - val_ethnicity_loss: 1.1372 - val_age_loss: 2.3269 - val_gender_accuracy: 0.6462 - val_ethnicity_accuracy: 0.5726 - val_age_accuracy: 0.1845\n",
      "Epoch 3/5\n",
      "156/156 [==============================] - 79s 504ms/step - loss: 2.4191 - gender_loss: 0.3371 - ethnicity_loss: 0.7721 - age_loss: 1.8645 - gender_accuracy: 0.8499 - ethnicity_accuracy: 0.7208 - age_accuracy: 0.3147 - val_loss: 2.8933 - val_gender_loss: 0.4716 - val_ethnicity_loss: 1.0079 - val_age_loss: 2.1536 - val_gender_accuracy: 0.8170 - val_ethnicity_accuracy: 0.6492 - val_age_accuracy: 0.2258\n",
      "Epoch 4/5\n",
      "156/156 [==============================] - 76s 485ms/step - loss: 2.2281 - gender_loss: 0.2726 - ethnicity_loss: 0.6721 - age_loss: 1.7558 - gender_accuracy: 0.8818 - ethnicity_accuracy: 0.7578 - age_accuracy: 0.3516 - val_loss: 2.8950 - val_gender_loss: 0.4150 - val_ethnicity_loss: 1.0894 - val_age_loss: 2.1427 - val_gender_accuracy: 0.8150 - val_ethnicity_accuracy: 0.6008 - val_age_accuracy: 0.2712\n",
      "Epoch 5/5\n",
      "156/156 [==============================] - 77s 496ms/step - loss: 2.0155 - gender_loss: 0.2166 - ethnicity_loss: 0.5630 - age_loss: 1.6258 - gender_accuracy: 0.9075 - ethnicity_accuracy: 0.7961 - age_accuracy: 0.3908 - val_loss: 2.8568 - val_gender_loss: 0.5682 - val_ethnicity_loss: 1.1577 - val_age_loss: 1.9938 - val_gender_accuracy: 0.7727 - val_ethnicity_accuracy: 0.6220 - val_age_accuracy: 0.3165\n"
     ]
    }
   ],
   "source": [
    "# %%wandb\n",
    "hist = model.fit_generator(train_dataset, validation_data=validation_dataset, \n",
    "                           epochs=config.epochs, \n",
    "                           steps_per_epoch=len(trainX)//config.batch_size, \n",
    "                           validation_steps=len(validationX)//config.batch_size,\n",
    "                           callbacks=[WandbCallback(), tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JeCNa3rX0Cyl"
   },
   "source": [
    "## Save your hard work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "cs_QAw-DDSM2",
    "outputId": "8fbdde29-72c8-4b25-a2ce-6a456168e64b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YOiSciWDHFWx",
    "outputId": "f9c9070e-783f-43a6-8bd2-0d1aaf277024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\tdatasets  images.zip  saved_model.pb  tmp  variables  wandb\n"
     ]
    }
   ],
   "source": [
    "!ls '/content/gdrive/My Drive/BlogforWandB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZY9hHZyM0o3p"
   },
   "outputs": [],
   "source": [
    "model.save('/content/gdrive/My Drive/BlogforWandB/datasets/model_5e.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pa1pvRd0ly64"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "UTK Face Attribute Classifier with TF2.0 and W&B",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
